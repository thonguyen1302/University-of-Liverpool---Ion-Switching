{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000000, 3)\n",
      "(2000000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>signal</th>\n",
       "      <th>open_channels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>-2.7600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-2.8557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>-2.4074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>-3.1404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>-3.1525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  signal  open_channels\n",
       "0  0.0001 -2.7600              0\n",
       "1  0.0002 -2.8557              0\n",
       "2  0.0003 -2.4074              0\n",
       "3  0.0004 -3.1404              0\n",
       "4  0.0005 -3.1525              0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.0001</td>\n",
       "      <td>-2.6498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500.0002</td>\n",
       "      <td>-2.8494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0003</td>\n",
       "      <td>-2.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500.0004</td>\n",
       "      <td>-2.4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500.0005</td>\n",
       "      <td>-2.6155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  signal\n",
       "0  500.0001 -2.6498\n",
       "1  500.0002 -2.8494\n",
       "2  500.0003 -2.8600\n",
       "3  500.0004 -2.4350\n",
       "4  500.0005 -2.6155"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a253582dd8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['open_channels'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN\n",
    "import numpy as np\n",
    "WINDOW_SIZE = 10\n",
    "def generator_data(train, batch_size, WINDOW_SIZE = 100):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for i in range(WINDOW_SIZE,train.shape[0]):\n",
    "        #print(\"DEBUG\", i)\n",
    "        feature = [[i]for i in train.to_numpy()[i-WINDOW_SIZE:i, 1]]\n",
    "        X_train.append(feature)\n",
    "        Y_train.append(int(train.to_numpy()[i,2]))\n",
    "        if (i-WINDOW_SIZE+1) % batch_size == 0:\n",
    "           # print(len(X_train))\n",
    "            #print(len(Y_train))\n",
    "            data_generate = (np.array(X_train), np.array(Y_train))\n",
    "            X_train = [] \n",
    "            Y_train = []\n",
    "            yield data_generate\n",
    "#data_generator = generator_data(train, batch_size=8, WINDOW_SIZE=WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-593bf33fb28b>:10: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-9-593bf33fb28b>:12: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"GatherV2:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"rnn/while/Exit_3:0\", shape=(?, 10), dtype=float32)\n",
      "WARNING:tensorflow:From C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\Anaconda3\\envs\\env_python3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 2.1696382 Acc : 0.0\n",
      "Loss : 2.1440134 Acc : 0.0\n",
      "Loss : 2.1181548 Acc : 0.0\n",
      "Loss : 2.0863383 Acc : 0.078125\n",
      "Loss : 2.059177 Acc : 0.71875\n",
      "Loss : 2.0323725 Acc : 1.0\n",
      "Loss : 2.0019016 Acc : 1.0\n",
      "Loss : 1.9711871 Acc : 1.0\n",
      "Loss : 1.9420967 Acc : 1.0\n",
      "Loss : 1.908423 Acc : 1.0\n",
      "Loss : 1.878536 Acc : 1.0\n",
      "Loss : 1.8478079 Acc : 1.0\n",
      "Loss : 1.8156109 Acc : 1.0\n",
      "Loss : 1.7777587 Acc : 1.0\n",
      "Loss : 1.7537059 Acc : 1.0\n",
      "Loss : 1.7140726 Acc : 1.0\n",
      "Loss : 1.6737674 Acc : 1.0\n",
      "Loss : 1.6419265 Acc : 1.0\n",
      "Loss : 1.6090187 Acc : 1.0\n",
      "Loss : 1.5614153 Acc : 1.0\n",
      "Loss : 1.5345461 Acc : 1.0\n",
      "Loss : 1.4970063 Acc : 1.0\n",
      "Loss : 1.4454002 Acc : 1.0\n",
      "Loss : 1.4114031 Acc : 1.0\n",
      "Loss : 1.3804079 Acc : 1.0\n",
      "Loss : 1.3282253 Acc : 1.0\n",
      "Loss : 1.2849497 Acc : 1.0\n",
      "Loss : 1.2497947 Acc : 1.0\n",
      "Loss : 1.2069068 Acc : 1.0\n",
      "Loss : 1.1623647 Acc : 1.0\n",
      "Loss : 1.1238163 Acc : 1.0\n",
      "Loss : 1.0750452 Acc : 1.0\n",
      "Loss : 1.0334879 Acc : 1.0\n",
      "Loss : 0.99047464 Acc : 1.0\n",
      "Loss : 0.9473272 Acc : 1.0\n",
      "Loss : 0.9059814 Acc : 1.0\n",
      "Loss : 0.8754465 Acc : 1.0\n",
      "Loss : 0.8283174 Acc : 1.0\n",
      "Loss : 0.7820718 Acc : 1.0\n",
      "Loss : 0.7512701 Acc : 1.0\n",
      "Loss : 0.7090183 Acc : 1.0\n",
      "Loss : 0.6675873 Acc : 1.0\n",
      "Loss : 0.6416312 Acc : 1.0\n",
      "Loss : 0.6044183 Acc : 1.0\n",
      "Loss : 0.5678443 Acc : 1.0\n",
      "Loss : 0.53858036 Acc : 1.0\n",
      "Loss : 0.50923276 Acc : 1.0\n",
      "Loss : 0.48104846 Acc : 1.0\n",
      "Loss : 0.45311898 Acc : 1.0\n",
      "Loss : 0.43096274 Acc : 1.0\n",
      "Loss : 0.402984 Acc : 1.0\n",
      "Loss : 0.38156408 Acc : 1.0\n",
      "Loss : 0.35981435 Acc : 1.0\n",
      "Loss : 0.33716494 Acc : 1.0\n",
      "Loss : 0.31913137 Acc : 1.0\n",
      "Loss : 0.3015907 Acc : 1.0\n",
      "Loss : 0.2833129 Acc : 1.0\n",
      "Loss : 0.26604015 Acc : 1.0\n",
      "Loss : 0.25349858 Acc : 1.0\n",
      "Loss : 0.23783386 Acc : 1.0\n",
      "Loss : 0.22362655 Acc : 1.0\n",
      "Loss : 0.21572813 Acc : 1.0\n",
      "Loss : 0.20116124 Acc : 1.0\n",
      "Loss : 0.18888101 Acc : 1.0\n",
      "Loss : 0.18104297 Acc : 1.0\n",
      "Loss : 0.1699889 Acc : 1.0\n",
      "Loss : 0.15944023 Acc : 1.0\n",
      "Loss : 0.15218371 Acc : 1.0\n",
      "Loss : 0.14460038 Acc : 1.0\n",
      "Loss : 0.13664475 Acc : 1.0\n",
      "Loss : 0.12930629 Acc : 1.0\n",
      "Loss : 0.12366019 Acc : 1.0\n",
      "Loss : 0.11559953 Acc : 1.0\n",
      "Loss : 0.111802846 Acc : 1.0\n",
      "Loss : 0.10572769 Acc : 1.0\n",
      "Loss : 0.09870434 Acc : 1.0\n",
      "Loss : 0.09459526 Acc : 1.0\n",
      "Loss : 0.09051111 Acc : 1.0\n",
      "Loss : 0.08513882 Acc : 1.0\n",
      "Loss : 0.081724934 Acc : 1.0\n",
      "Loss : 0.07734081 Acc : 1.0\n",
      "Loss : 0.0734276 Acc : 1.0\n",
      "Loss : 0.06930503 Acc : 1.0\n",
      "Loss : 0.06668816 Acc : 1.0\n",
      "Loss : 0.06324144 Acc : 1.0\n",
      "Loss : 0.060028464 Acc : 1.0\n",
      "Loss : 0.057457935 Acc : 1.0\n",
      "Loss : 0.054463826 Acc : 1.0\n",
      "Loss : 0.05173572 Acc : 1.0\n",
      "Loss : 0.04980684 Acc : 1.0\n",
      "Loss : 0.04693783 Acc : 1.0\n",
      "Loss : 0.045016997 Acc : 1.0\n",
      "Loss : 0.042989653 Acc : 1.0\n",
      "Loss : 0.040974252 Acc : 1.0\n",
      "Loss : 0.03887974 Acc : 1.0\n",
      "Loss : 0.037217587 Acc : 1.0\n",
      "Loss : 0.035628233 Acc : 1.0\n",
      "Loss : 0.03367272 Acc : 1.0\n",
      "Loss : 0.03220114 Acc : 1.0\n",
      "Loss : 0.029256672 Acc : 1.0\n",
      "Loss : 0.027971774 Acc : 1.0\n",
      "Loss : 0.026844563 Acc : 1.0\n",
      "Loss : 0.025295515 Acc : 1.0\n",
      "Loss : 0.024225865 Acc : 1.0\n",
      "Loss : 0.023263302 Acc : 1.0\n",
      "Loss : 0.022176225 Acc : 1.0\n",
      "Loss : 0.021023154 Acc : 1.0\n",
      "Loss : 0.020228375 Acc : 1.0\n",
      "Loss : 0.019259937 Acc : 1.0\n",
      "Loss : 0.4585759 Acc : 0.921875\n",
      "Loss : 0.020040222 Acc : 1.0\n",
      "Loss : 0.019052658 Acc : 1.0\n",
      "Loss : 0.018181572 Acc : 1.0\n",
      "Loss : 0.017450372 Acc : 1.0\n",
      "Loss : 0.016664779 Acc : 1.0\n",
      "Loss : 0.015792167 Acc : 1.0\n",
      "Loss : 0.015106792 Acc : 1.0\n",
      "Loss : 0.014479847 Acc : 1.0\n",
      "Loss : 0.0137380855 Acc : 1.0\n",
      "Loss : 0.0131814005 Acc : 1.0\n",
      "Loss : 0.012621822 Acc : 1.0\n",
      "Loss : 0.012007408 Acc : 1.0\n",
      "Loss : 0.011470428 Acc : 1.0\n",
      "Loss : 0.010985864 Acc : 1.0\n",
      "Loss : 0.01042818 Acc : 1.0\n",
      "Loss : 0.01004599 Acc : 1.0\n",
      "Loss : 0.0096135205 Acc : 1.0\n",
      "Loss : 0.009107981 Acc : 1.0\n",
      "Loss : 0.008761713 Acc : 1.0\n",
      "Loss : 0.008364208 Acc : 1.0\n",
      "Loss : 0.0079741385 Acc : 1.0\n",
      "Loss : 0.0075932923 Acc : 1.0\n",
      "Loss : 0.007335853 Acc : 1.0\n",
      "Loss : 0.0069534006 Acc : 1.0\n",
      "Loss : 0.0066408105 Acc : 1.0\n",
      "Loss : 0.0064152423 Acc : 1.0\n",
      "Loss : 0.0061098076 Acc : 1.0\n",
      "Loss : 0.00584412 Acc : 1.0\n",
      "Loss : 0.0055878377 Acc : 1.0\n",
      "Loss : 0.005372758 Acc : 1.0\n",
      "Loss : 0.005109225 Acc : 1.0\n",
      "Loss : 0.004921194 Acc : 1.0\n",
      "Loss : 0.0046962285 Acc : 1.0\n",
      "Loss : 0.0044601923 Acc : 1.0\n",
      "Loss : 0.004292311 Acc : 1.0\n",
      "Loss : 0.004101502 Acc : 1.0\n",
      "Loss : 0.0039133467 Acc : 1.0\n",
      "Loss : 0.0037498865 Acc : 1.0\n",
      "Loss : 0.003607751 Acc : 1.0\n",
      "Loss : 0.52369696 Acc : 0.921875\n",
      "Loss : 0.0042980667 Acc : 1.0\n",
      "Loss : 0.0041753044 Acc : 1.0\n",
      "Loss : 0.0040451945 Acc : 1.0\n",
      "Loss : 0.0038912075 Acc : 1.0\n",
      "Loss : 0.0038276394 Acc : 1.0\n",
      "Loss : 0.0036613066 Acc : 1.0\n",
      "Loss : 0.003528262 Acc : 1.0\n",
      "Loss : 0.0034554983 Acc : 1.0\n",
      "Loss : 0.0033425284 Acc : 1.0\n",
      "Loss : 0.003209962 Acc : 1.0\n",
      "Loss : 0.0031043075 Acc : 1.0\n",
      "Loss : 0.0030000452 Acc : 1.0\n",
      "Loss : 0.0028885962 Acc : 1.0\n",
      "Loss : 0.0028043857 Acc : 1.0\n",
      "Loss : 0.0027148407 Acc : 1.0\n",
      "Loss : 0.0026093186 Acc : 1.0\n",
      "Loss : 0.0025270893 Acc : 1.0\n",
      "Loss : 0.0024434114 Acc : 1.0\n",
      "Loss : 0.0023604613 Acc : 1.0\n",
      "Loss : 0.0022788134 Acc : 1.0\n",
      "Loss : 0.0022054764 Acc : 1.0\n",
      "Loss : 0.0021204925 Acc : 1.0\n",
      "Loss : 0.002055884 Acc : 1.0\n",
      "Loss : 0.0019879402 Acc : 1.0\n",
      "Loss : 0.0019135014 Acc : 1.0\n",
      "Loss : 0.0018356437 Acc : 1.0\n",
      "Loss : 0.0017840357 Acc : 1.0\n",
      "Loss : 0.0017157294 Acc : 1.0\n",
      "Loss : 0.0016523015 Acc : 1.0\n",
      "Loss : 0.0015984059 Acc : 1.0\n",
      "Loss : 0.0015434325 Acc : 1.0\n",
      "Loss : 0.0014810408 Acc : 1.0\n",
      "Loss : 0.00143099 Acc : 1.0\n",
      "Loss : 0.0013836375 Acc : 1.0\n",
      "Loss : 0.001327514 Acc : 1.0\n",
      "Loss : 0.0012825116 Acc : 1.0\n",
      "Loss : 0.001237403 Acc : 1.0\n",
      "Loss : 0.0011870853 Acc : 1.0\n",
      "Loss : 0.0011479019 Acc : 1.0\n",
      "Loss : 0.0011065791 Acc : 1.0\n",
      "Loss : 0.0010662538 Acc : 1.0\n",
      "Loss : 0.001023011 Acc : 1.0\n",
      "Loss : 0.0009835757 Acc : 1.0\n",
      "Loss : 0.00094778044 Acc : 1.0\n",
      "Loss : 0.0009108246 Acc : 1.0\n",
      "Loss : 0.000878477 Acc : 1.0\n",
      "Loss : 0.0008436867 Acc : 1.0\n",
      "Loss : 0.0008113723 Acc : 1.0\n",
      "Loss : 0.00075154623 Acc : 1.0\n",
      "Loss : 0.0007236141 Acc : 1.0\n",
      "Loss : 0.00069606653 Acc : 1.0\n",
      "Loss : 0.00066784443 Acc : 1.0\n",
      "Loss : 0.0006393497 Acc : 1.0\n",
      "Loss : 0.0006177063 Acc : 1.0\n",
      "Loss : 0.00059409667 Acc : 1.0\n",
      "Loss : 0.00057002297 Acc : 1.0\n",
      "Loss : 0.00054874667 Acc : 1.0\n",
      "Loss : 0.0005271721 Acc : 1.0\n",
      "Loss : 0.0005028827 Acc : 1.0\n",
      "Loss : 0.0004861495 Acc : 1.0\n",
      "Loss : 0.00046670905 Acc : 1.0\n",
      "Loss : 0.0004466761 Acc : 1.0\n",
      "Loss : 0.00042898502 Acc : 1.0\n",
      "Loss : 0.00041407155 Acc : 1.0\n",
      "Loss : 0.00039429264 Acc : 1.0\n",
      "Loss : 0.00037990557 Acc : 1.0\n",
      "Loss : 0.00036531533 Acc : 1.0\n",
      "Loss : 0.00035027982 Acc : 1.0\n",
      "Loss : 0.0003347842 Acc : 1.0\n",
      "Loss : 0.00032179282 Acc : 1.0\n",
      "Loss : 0.00030803966 Acc : 1.0\n",
      "Loss : 0.00029596777 Acc : 1.0\n",
      "Loss : 0.00028434634 Acc : 1.0\n",
      "Loss : 0.00027203024 Acc : 1.0\n",
      "Loss : 0.00026060222 Acc : 1.0\n",
      "Loss : 0.00025046646 Acc : 1.0\n",
      "Loss : 0.00023960619 Acc : 1.0\n",
      "Loss : 0.00022932491 Acc : 1.0\n",
      "Loss : 0.00022088159 Acc : 1.0\n",
      "Loss : 0.0002117529 Acc : 1.0\n",
      "Loss : 0.00020220321 Acc : 1.0\n",
      "Loss : 0.00019467963 Acc : 1.0\n",
      "Loss : 0.00018625648 Acc : 1.0\n",
      "Loss : 0.0001783454 Acc : 1.0\n",
      "Loss : 2.5981367 Acc : 0.703125\n",
      "Loss : 5.745869 Acc : 0.3125\n",
      "Loss : 1.0324173 Acc : 0.875\n",
      "Loss : 3.0008466 Acc : 0.625\n",
      "Loss : 4.999762 Acc : 0.34375\n",
      "Loss : 4.9241667 Acc : 0.328125\n",
      "Loss : 5.85349 Acc : 0.140625\n",
      "Loss : 1.4854698 Acc : 0.78125\n",
      "Loss : 0.0008017043 Acc : 1.0\n",
      "Loss : 0.00079313724 Acc : 1.0\n",
      "Loss : 0.00082195067 Acc : 1.0\n",
      "Loss : 0.0007756866 Acc : 1.0\n",
      "Loss : 0.0007742479 Acc : 1.0\n",
      "Loss : 0.00078428537 Acc : 1.0\n",
      "Loss : 0.00076645904 Acc : 1.0\n",
      "Loss : 0.0007650852 Acc : 1.0\n",
      "Loss : 0.0007686664 Acc : 1.0\n",
      "Loss : 0.00075065903 Acc : 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.nn.rnn_cell import BasicRNNCell\n",
    "tf.reset_default_graph()\n",
    "sess=tf.Session()\n",
    "\n",
    "WINDOW_SIZE = 100\n",
    "signal = tf.placeholder(tf.float32, [None, WINDOW_SIZE, 1])\n",
    "channel = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "rnn = BasicRNNCell(num_units=10)\n",
    "\n",
    "output, state = tf.nn.dynamic_rnn(rnn, signal, dtype=tf.float32)\n",
    "# Get output of RNN sequence\n",
    "output = tf.transpose(output, [1, 0, 2])\n",
    "last = tf.gather(output, int(output.get_shape()[0]) - 1)\n",
    "\n",
    "print(last)\n",
    "print(state)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([10, 10], stddev=0.1))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "logits_out = tf.matmul(last, weight) + bias\n",
    "\n",
    "# Loss function\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_out, labels=channel)\n",
    "loss = tf.reduce_mean(losses)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits_out, 1), tf.cast(channel, tf.int64)), tf.float32))\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(0.005)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "# Start training\n",
    "data_generator = generator_data(train, batch_size=64, WINDOW_SIZE=WINDOW_SIZE)\n",
    "for epoch in range(int(5000000/64)):\n",
    "    (x_train, y_train) = next(data_generator)\n",
    "    # Shuffle training data\n",
    "    shuffled_ix = np.random.permutation(np.arange(len(x_train)))\n",
    "    x_train = x_train[shuffled_ix]\n",
    "    y_train = y_train[shuffled_ix]\n",
    "    sess.run(train_step, feed_dict={signal:x_train,channel:y_train})\n",
    "    \n",
    "    if epoch % 100:\n",
    "        # Run loss and accuracy for training\n",
    "        temp_train_loss, temp_train_acc = sess.run([loss, accuracy], feed_dict={signal:x_train,channel:y_train})\n",
    "        train_loss.append(temp_train_loss)\n",
    "        train_accuracy.append(temp_train_acc)\n",
    "        print(\"Loss :\", temp_train_loss, \"Acc :\", temp_train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "WINDOW_SIZE = 10\n",
    "def generator_data_test(test, batch_size, WINDOW_SIZE = 100):\n",
    "    X_train = []\n",
    "    for i in range(WINDOW_SIZE,train.shape[0]):\n",
    "        #print(\"DEBUG\", i)\n",
    "        feature = [[i]for i in train.to_numpy()[i-WINDOW_SIZE:i, 1]]\n",
    "        X_train.append(feature)\n",
    "        if (i-WINDOW_SIZE+1) % batch_size == 0:\n",
    "           # print(len(X_train))\n",
    "            #print(len(Y_train))\n",
    "            data_generate = (np.array(X_train))\n",
    "            X_train = [] \n",
    "            yield data_generate\n",
    "test_data_generator = generator_data_test(test, batch_size, WINDOW_SIZE = 100)\n",
    "x_test = next(test_data_generator)  # x_test.shape(batchsize, 100)  \n",
    "x_test_predict = sess.run(tf.nn.softmax(logits_out), feed_dict={signal:x_test})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
